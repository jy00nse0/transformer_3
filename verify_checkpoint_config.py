#!/usr/bin/env python3
"""
μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ° λ΅λ“ κ²€μ¦ μ¤ν¬λ¦½νΈ

μ΄ μ¤ν¬λ¦½νΈλ” λ‹¤μμ„ κ²€μ¦ν•©λ‹λ‹¤:
1. λ¨λΈ ν•™μµ μ‹ μ„¤μ •ν• argumentsκ°€ μ²΄ν¬ν¬μΈνΈμ— μ €μ¥λλ”μ§€
2. inference.pyμ—μ„ μ²΄ν¬ν¬μΈνΈλ΅λ¶€ν„° λ¨λΈ μ„¤μ •μ„ μ¬λ°”λ¥΄κ² λ΅λ“ν•λ”μ§€
"""

import torch
import sys
from pathlib import Path

def test_checkpoint_save():
    """μ²΄ν¬ν¬μΈνΈμ— model_configκ°€ μ €μ¥λλ”μ§€ ν…μ¤νΈ"""
    print("="*80)
    print("TEST 1: μ²΄ν¬ν¬μΈνΈ μ €μ¥ κ²€μ¦")
    print("="*80)
    
    # ν…μ¤νΈμ© λ¨λΈ μ„¤μ •
    model_config = {
        'd_model': 256,
        'n_head': 4,
        'n_layers': 3,
        'ffn_hidden': 1024,
        'drop_prob': 0.2,
        'max_len': 128,
        'enc_voc_size': 10000,
        'dec_voc_size': 10000,
        'src_pad_idx': 0,
        'trg_pad_idx': 0,
        'trg_sos_idx': 1,
        'label_smoothing': 0.15,
        'kdim': 128
    }
    
    # μ„μ‹ μ²΄ν¬ν¬μΈνΈ μ €μ¥
    test_checkpoint = {
        'step': 1000,
        'epoch': 1,
        'model_state_dict': {},  # λΉ state dict (ν…μ¤νΈμ©)
        'optimizer_state_dict': {},
        'scheduler_state_dict': {},
        'val_loss': 3.5,
        'model_config': model_config,
    }
    
    test_path = Path('/tmp/test_checkpoint.pt')
    torch.save(test_checkpoint, test_path)
    print(f"\nβ“ ν…μ¤νΈ μ²΄ν¬ν¬μΈνΈ μ €μ¥: {test_path}")
    
    # λ΅λ“ λ° κ²€μ¦
    loaded = torch.load(test_path, map_location='cpu')
    
    print("\nμ²΄ν¬ν¬μΈνΈμ— μ €μ¥λ λ‚΄μ©:")
    print(f"  Keys: {list(loaded.keys())}")
    
    if 'model_config' in loaded:
        print("\nβ“ model_configκ°€ μ²΄ν¬ν¬μΈνΈμ— ν¬ν•¨λμ–΄ μμµλ‹λ‹¤!")
        print("\nμ €μ¥λ model_config:")
        for key, value in loaded['model_config'].items():
            print(f"  {key}: {value}")
        
        # κ²€μ¦
        print("\nκ²€μ¦ κ²°κ³Ό:")
        all_match = True
        for key, expected_value in model_config.items():
            actual_value = loaded['model_config'].get(key)
            if actual_value == expected_value:
                print(f"  β“ {key}: {actual_value}")
            else:
                print(f"  β— {key}: expected {expected_value}, got {actual_value}")
                all_match = False
        
        if all_match:
            print("\nβ… TEST 1 PASSED: λ¨λ“  μ„¤μ •μ΄ μ¬λ°”λ¥΄κ² μ €μ¥λμ—μµλ‹λ‹¤!")
        else:
            print("\nβ TEST 1 FAILED: μΌλ¶€ μ„¤μ •μ΄ μ¬λ°”λ¥΄κ² μ €μ¥λμ§€ μ•μ•μµλ‹λ‹¤!")
            return False
    else:
        print("\nβ TEST 1 FAILED: model_configκ°€ μ²΄ν¬ν¬μΈνΈμ— μ—†μµλ‹λ‹¤!")
        return False
    
    # μ •λ¦¬
    test_path.unlink()
    return True

def test_checkpoint_load():
    """inference.pyκ°€ μ²΄ν¬ν¬μΈνΈμ—μ„ model_configλ¥Ό μ¬λ°”λ¥΄κ² λ΅λ“ν•λ”μ§€ ν…μ¤νΈ"""
    print("\n" + "="*80)
    print("TEST 2: μ²΄ν¬ν¬μΈνΈ λ΅λ“ κ²€μ¦ (inference.py μ‹λ®¬λ μ΄μ…)")
    print("="*80)
    
    # ν…μ¤νΈμ© μ²΄ν¬ν¬μΈνΈ μƒμ„±
    model_config = {
        'd_model': 256,
        'n_head': 4,
        'n_layers': 3,
        'ffn_hidden': 1024,
        'drop_prob': 0.2,
        'max_len': 128,
        'kdim': 128
    }
    
    test_checkpoint = {
        'step': 1000,
        'epoch': 1,
        'model_state_dict': {},
        'model_config': model_config,
    }
    
    # μ„μ‹ λ””λ ‰ν† λ¦¬ μƒμ„±
    test_dir = Path('/tmp/test_checkpoints')
    test_dir.mkdir(exist_ok=True)
    
    test_path = test_dir / 'model_step_1000.pt'
    torch.save(test_checkpoint, test_path)
    print(f"\nβ“ ν…μ¤νΈ μ²΄ν¬ν¬μΈνΈ μ €μ¥: {test_path}")
    
    # inference.pyμ λ΅μ§ μ‹λ®¬λ μ΄μ…
    print("\ninference.py λ΅μ§ μ‹λ®¬λ μ΄μ…:")
    
    # μ²΄ν¬ν¬μΈνΈ νμΌ μ°ΎκΈ°
    checkpoint_files = sorted(test_dir.glob('model_step_*.pt'))
    print(f"  μ°Ύμ€ μ²΄ν¬ν¬μΈνΈ: {len(checkpoint_files)}κ°")
    
    if not checkpoint_files:
        print("  β μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤!")
        return False
    
    # μ²« λ²μ§Έ μ²΄ν¬ν¬μΈνΈμ—μ„ config λ΅λ“
    first_checkpoint = torch.load(checkpoint_files[0], map_location='cpu')
    
    if 'model_config' in first_checkpoint:
        loaded_config = first_checkpoint['model_config']
        print("\nβ“ model_config λ΅λ“ μ„±κ³µ!")
        print("\nλ΅λ“λ μ„¤μ •:")
        for key, value in loaded_config.items():
            print(f"  {key}: {value}")
        
        # κ²€μ¦
        print("\nκ²€μ¦ κ²°κ³Ό:")
        all_match = True
        for key, expected_value in model_config.items():
            actual_value = loaded_config.get(key)
            if actual_value == expected_value:
                print(f"  β“ {key}: {actual_value}")
            else:
                print(f"  β— {key}: expected {expected_value}, got {actual_value}")
                all_match = False
        
        if all_match:
            print("\nβ… TEST 2 PASSED: λ¨λ“  μ„¤μ •μ΄ μ¬λ°”λ¥΄κ² λ΅λ“λμ—μµλ‹λ‹¤!")
            
            # λ¨λΈ μ΄κΈ°ν™” κ°€λ¥ μ—¬λ¶€ ν™•μΈ
            print("\nλ¨λΈ μ΄κΈ°ν™”μ— ν•„μ”ν• νλΌλ―Έν„°:")
            required_params = ['d_model', 'n_head', 'max_len', 'ffn_hidden', 'n_layers', 'drop_prob']
            all_present = True
            for param in required_params:
                if param in loaded_config:
                    print(f"  β“ {param}: {loaded_config[param]}")
                else:
                    print(f"  β— {param}: μ—†μ")
                    all_present = False
            
            if all_present:
                print("\nβ… λ¨λΈ μ΄κΈ°ν™”μ— ν•„μ”ν• λ¨λ“  νλΌλ―Έν„°κ°€ μ΅΄μ¬ν•©λ‹λ‹¤!")
            else:
                print("\nβ μΌλ¶€ ν•„μ νλΌλ―Έν„°κ°€ μ—†μµλ‹λ‹¤!")
                all_match = False
        else:
            print("\nβ TEST 2 FAILED: μΌλ¶€ μ„¤μ •μ΄ μ¬λ°”λ¥΄κ² λ΅λ“λμ§€ μ•μ•μµλ‹λ‹¤!")
            return False
    else:
        print("\nβ TEST 2 FAILED: model_configλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤!")
        return False
    
    # μ •λ¦¬
    test_path.unlink()
    test_dir.rmdir()
    return True

def test_checkpoint_averaging():
    """checkpoint averaging μ‹ model_configκ°€ λ³΄μ΅΄λλ”μ§€ ν…μ¤νΈ"""
    print("\n" + "="*80)
    print("TEST 3: μ²΄ν¬ν¬μΈνΈ Averaging μ‹ model_config λ³΄μ΅΄ κ²€μ¦")
    print("="*80)
    
    # ν…μ¤νΈμ© μ²΄ν¬ν¬μΈνΈλ“¤ μƒμ„±
    model_config = {
        'd_model': 512,
        'n_head': 8,
        'n_layers': 6,
        'ffn_hidden': 2048,
        'drop_prob': 0.1,
        'max_len': 256,
        'kdim': None
    }
    
    test_dir = Path('/tmp/test_avg_checkpoints')
    test_dir.mkdir(exist_ok=True)
    
    # 3κ°μ μ²΄ν¬ν¬μΈνΈ μƒμ„±
    for i in range(1, 4):
        test_checkpoint = {
            'step': i * 1000,
            'epoch': i,
            'model_state_dict': {'dummy_param': torch.randn(10, 10)},
            'model_config': model_config,
        }
        test_path = test_dir / f'model_step_{i*1000}.pt'
        torch.save(test_checkpoint, test_path)
        print(f"  μƒμ„±: {test_path.name}")
    
    # checkpoint_averaging.pyμ average_checkpoints ν•¨μ μ‹λ®¬λ μ΄μ…
    print("\ncheckpoint averaging μ‹λ®¬λ μ΄μ…:")
    
    checkpoint_files = sorted(test_dir.glob('model_step_*.pt'))
    checkpoints = []
    for path in checkpoint_files:
        ckpt = torch.load(path, map_location='cpu')
        checkpoints.append(ckpt)
    
    # Averaged checkpoint μƒμ„±
    averaged_checkpoint = {
        'model_state_dict': {},  # μ‹¤μ λ΅λ” ν‰κ· ν™”λ state dict
        'averaged_from': [str(p) for p in checkpoint_files],
        'num_checkpoints': len(checkpoint_files),
    }
    
    # last checkpointμ—μ„ model_config λ³΄μ΅΄
    if 'model_config' in checkpoints[-1]:
        averaged_checkpoint['model_config'] = checkpoints[-1]['model_config']
        print("  β“ model_configκ°€ averaged checkpointμ— ν¬ν•¨λ¨")
    
    # κ²€μ¦
    if 'model_config' in averaged_checkpoint:
        loaded_config = averaged_checkpoint['model_config']
        print("\nβ“ Averaged checkpointμ— model_config μ΅΄μ¬!")
        print("\nλ³΄μ΅΄λ μ„¤μ •:")
        for key, value in loaded_config.items():
            print(f"  {key}: {value}")
        
        # κ²€μ¦
        print("\nκ²€μ¦ κ²°κ³Ό:")
        all_match = True
        for key, expected_value in model_config.items():
            actual_value = loaded_config.get(key)
            if actual_value == expected_value:
                print(f"  β“ {key}: {actual_value}")
            else:
                print(f"  β— {key}: expected {expected_value}, got {actual_value}")
                all_match = False
        
        if all_match:
            print("\nβ… TEST 3 PASSED: Averaging ν›„μ—λ„ model_configκ°€ λ³΄μ΅΄λ©λ‹λ‹¤!")
        else:
            print("\nβ TEST 3 FAILED: μΌλ¶€ μ„¤μ •μ΄ μ¬λ°”λ¥΄κ² λ³΄μ΅΄λμ§€ μ•μ•μµλ‹λ‹¤!")
            return False
    else:
        print("\nβ TEST 3 FAILED: Averaged checkpointμ— model_configκ°€ μ—†μµλ‹λ‹¤!")
        return False
    
    # μ •λ¦¬
    for f in test_dir.glob('*.pt'):
        f.unlink()
    test_dir.rmdir()
    return True

def main():
    """λ¨λ“  ν…μ¤νΈ μ‹¤ν–‰"""
    print("\n" + "="*80)
    print("  μ²΄ν¬ν¬μΈνΈ model_config μ €μ¥/λ΅λ“ κ²€μ¦ μ¤ν¬λ¦½νΈ")
    print("="*80)
    
    results = []
    
    # TEST 1: μ²΄ν¬ν¬μΈνΈ μ €μ¥
    results.append(("μ²΄ν¬ν¬μΈνΈ μ €μ¥", test_checkpoint_save()))
    
    # TEST 2: μ²΄ν¬ν¬μΈνΈ λ΅λ“
    results.append(("μ²΄ν¬ν¬μΈνΈ λ΅λ“", test_checkpoint_load()))
    
    # TEST 3: Checkpoint averaging
    results.append(("Checkpoint Averaging", test_checkpoint_averaging()))
    
    # μµμΆ… κ²°κ³Ό
    print("\n" + "="*80)
    print("μµμΆ… κ²€μ¦ κ²°κ³Ό")
    print("="*80)
    
    all_passed = True
    for test_name, passed in results:
        status = "β… PASSED" if passed else "β FAILED"
        print(f"  {test_name}: {status}")
        if not passed:
            all_passed = False
    
    print("="*80)
    
    if all_passed:
        print("\nπ‰ λ¨λ“  ν…μ¤νΈ ν†µκ³Ό!")
        print("\nκ²€μ¦ μ™„λ£:")
        print("  1. β“ λ¨λΈ ν•™μµ μ‹ argumentsκ°€ μ²΄ν¬ν¬μΈνΈμ— μ €μ¥λ¨")
        print("  2. β“ inference.pyκ°€ μ²΄ν¬ν¬μΈνΈμ—μ„ μ„¤μ •μ„ μ¬λ°”λ¥΄κ² λ΅λ“ν•¨")
        print("  3. β“ Checkpoint averaging ν›„μ—λ„ μ„¤μ •μ΄ λ³΄μ΅΄λ¨")
        return 0
    else:
        print("\nβ οΈ  μΌλ¶€ ν…μ¤νΈ μ‹¤ν¨!")
        return 1

if __name__ == '__main__':
    sys.exit(main())
